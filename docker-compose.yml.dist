version: "3.1"

services:
  elasticsearch:
    container_name: "${NAME}_elasticsearch"
    image: khezen/elasticsearch:6.2.2
    environment:
      - "CLUSTER_NAME=developers-italia"
      - "ELASTIC_PWD=${ELASTIC_PWD}"
      - "KIBANA_PWD=${KIBANA_PWD}"
      - "ES_TMPDIR=/tmp"
      - "HTTP_SSL=false"
    labels:
      - "traefik.enable=true"
      - 'traefik.backend=elasticsearch'
      - 'traefik.port=9200'
      - 'traefik.frontend.rule=Host:elasticsearch.${PROJECT_BASE_URL};Path:/publiccode/_search;Method:GET,OPTIONS,POST'
      - "traefik.frontend.headers.customRequestHeaders=Authorization: Basic ${ELASTIC_BASIC_AUTH_TOKEN}"
      - "traefik.frontend.headers.customResponseHeaders.Access-Control-Allow-Origin = '*'"
      - "traefik.frontend.rateLimit.extractorFunc=client.ip"
      - "traefik.frontend.rateLimit.rateSet.elasticsearch.period=60s"
      - "traefik.frontend.rateLimit.rateSet.elasticsearch.average=100"
      - "traefik.frontend.rateLimit.rateSet.elasticsearch.burst=200"
    networks:
      - web
    volumes:
      - es_data:/elasticsearch/data
      - ./docker/elasticsearch/config/elasticsearch.yml:/elasticsearch/config/elasticsearch.yml
      - ./elasticsearch:/opt/elasticsearch

  kibana:
    container_name: "${NAME}_kibana"
    image: khezen/kibana:6.2.2
    environment:
      - "ELASTICSEARCH_PROTOCOL=http"
      - "ELASTICSEARCH_HOST=elasticsearch"
      - "ELASTICSEARCH_PORT=9200"
      - "KIBANA_PWD=${KIBANA_PWD}"
    labels:
      - "traefik.enable=true"
      - 'traefik.backend=kibana'
      - 'traefik.port=5601'
      - 'traefik.frontend.rule=Host:kibana.${PROJECT_BASE_URL}'
    networks:
      - web
    volumes:
      - ./docker/kibana/config/kibana.yml:/opt/kibana-6.2.2-linux-x86_64/config/kibana.yml
      - ./elasticsearch:/opt/elasticsearch

  prometheus:
    container_name: "${NAME}_prometheus"
    image: quay.io/prometheus/prometheus:v2.2.1
    labels:
      - "traefik.enable=true"
      - 'traefik.backend=prometheus'
      - 'traefik.port=9090'
      - 'traefik.frontend.rule=Host:prometheus.${PROJECT_BASE_URL}'
    networks:
      - web
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  proxy:
   command: --api --docker --docker.exposedByDefault=false --logLevel=DEBUG
   container_name: "${NAME}_proxy"
   image: containous/traefik:experimental
   networks:
     - web
   ports:
     - "80:80"
     - "443:443"
     - "8080:8080"
   volumes:
     - /var/run/docker.sock:/var/run/docker.sock

  redis:
    container_name: "${NAME}_redis"
    image: redis:4.0
    networks:
      - web

  php:
    image: wodby/php:7.1-4.3.0
    container_name: ${NAME}_php
    networks:
      - web
    expose:
      - 9000
    volumes:
      - "./elasticsearch/php:/var/www/php"
    environment:
      PHP_SENDMAIL_PATH: /usr/sbin/sendmail -t -i -S mailhog:1025
      PHP_XDEBUG_IDEKEY: phpstorm
      PHP_MAX_EXECUTION_TIME: 120
      PHP_MEMORY_LIMIT: 512M
      PHP_POST_MAX_SIZE: 16M
      PHP_UPLOAD_MAX_FILESIZE: 16M
      PHP_FPM_CLEAR_ENV: 'no'

  httpd:
    image: wodby/php-apache:2.4-3.0.5
    container_name: ${NAME}_httpd
    networks:
      - web
    labels:
      - "traefik.enable=true"
      - 'traefik.backend=httpd'
      - 'traefik.port=80'
      - 'traefik.frontend.rule=Host:web.${PROJECT_BASE_URL}'
    volumes:
      - "./elasticsearch/html:/var/www/html"

# De-comment next lines after build a local image for the crawler.
#  crawler:
#    environment:
#      - "CRAWLED_FILENAME=${CRAWLED_FILENAME}"
#    container_name: "${NAME}_crawler"
#    image: italia/developers-italia-backend:0.0.1
#    ports:
#      - 8081:8081
#    networks:
#      - web
#    volumes:
#      - ./data:/app/data

volumes:
  es_data:
    driver: local

networks:
  web:
